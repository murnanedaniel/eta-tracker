{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysing binned pseudorapidity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System imports\n",
    "import os\n",
    "import sys\n",
    "from pprint import pprint as pp\n",
    "from time import time as tt\n",
    "import pickle\n",
    "\n",
    "# External imports\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.colors\n",
    "import numpy as np\n",
    "import multiprocessing as mp\n",
    "from functools import partial\n",
    "\n",
    "from trackml.dataset import load_event\n",
    "from trackml.randomize import shuffle_hits\n",
    "from trackml.score import score_event\n",
    "\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.distributed import DistributedSampler\n",
    "import torch_geometric\n",
    "from torch_geometric.data import Data\n",
    "\n",
    "# Limit CPU usage on Jupyter\n",
    "os.environ['OMP_NUM_THREADS'] = '4'\n",
    "\n",
    "# Pick up local packages\n",
    "sys.path.append('..')\n",
    "\n",
    "# Locals\n",
    "\n",
    "from prepareTracks import *\n",
    "from nb_utils import *\n",
    "from gpu_utils import *\n",
    "from datasets import get_data_loaders\n",
    "from trainers import get_trainer\n",
    "import distributed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make File List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_dir = '/global/cscratch1/sd/danieltm/ExaTrkX/trackml/train_100_events/'\n",
    "output_dir = '/global/u2/d/danieltm/ExaTrkX/eta-tracker/data/numba_testing'\n",
    "n_files = 32\n",
    "n_workers = 32\n",
    "config = {'selection': {'pt_min': 0.5,\n",
    "    'phi_slope_max': 0.0006,\n",
    "    'z0_max': 150,\n",
    "    'n_phi_sections': 1,\n",
    "    'n_eta_sections': 1,\n",
    "    'eta_range': [-5, 5]}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_files = os.listdir(input_dir)\n",
    "suffix = '-hits.csv'\n",
    "file_prefixes = sorted(os.path.join(input_dir, f.replace(suffix, ''))\n",
    "                       for f in all_files if f.endswith(suffix))\n",
    "file_prefixes = np.array(file_prefixes[:n_files])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## CPU Threading (for comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../prepareTracks.py:213: RuntimeWarning: invalid value encountered in arccos\n",
      "  theta = np.arccos(p_zr[0])\n",
      "/global/homes/d/danieltm/.local/lib/python3.7/site-packages/scipy/optimize/minpack.py:449: RuntimeWarning: gtol=0.000000 is too small, func(x) is orthogonal to the columns of\n",
      "  the Jacobian to machine precision.\n",
      "  warnings.warn(errors[info][0], RuntimeWarning)\n",
      "../prepareTracks.py:213: RuntimeWarning: invalid value encountered in arccos\n",
      "  theta = np.arccos(p_zr[0])\n",
      "/global/homes/d/danieltm/.local/lib/python3.7/site-packages/scipy/optimize/minpack.py:449: RuntimeWarning: gtol=0.000000 is too small, func(x) is orthogonal to the columns of\n",
      "  the Jacobian to machine precision.\n",
      "  warnings.warn(errors[info][0], RuntimeWarning)\n",
      "../prepareTracks.py:213: RuntimeWarning: invalid value encountered in arccos\n",
      "  theta = np.arccos(p_zr[0])\n",
      "../prepareTracks.py:213: RuntimeWarning: invalid value encountered in arccos\n",
      "  theta = np.arccos(p_zr[0])\n",
      "../prepareTracks.py:213: RuntimeWarning: invalid value encountered in arccos\n",
      "  theta = np.arccos(p_zr[0])\n",
      "../prepareTracks.py:213: RuntimeWarning: invalid value encountered in arccos\n",
      "  theta = np.arccos(p_zr[0])\n",
      "../prepareTracks.py:213: RuntimeWarning: invalid value encountered in arccos\n",
      "  theta = np.arccos(p_zr[0])\n",
      "../prepareTracks.py:213: RuntimeWarning: invalid value encountered in arccos\n",
      "  theta = np.arccos(p_zr[0])\n",
      "/global/homes/d/danieltm/.local/lib/python3.7/site-packages/scipy/optimize/minpack.py:449: RuntimeWarning: gtol=0.000000 is too small, func(x) is orthogonal to the columns of\n",
      "  the Jacobian to machine precision.\n",
      "  warnings.warn(errors[info][0], RuntimeWarning)\n",
      "../prepareTracks.py:213: RuntimeWarning: invalid value encountered in arccos\n",
      "  theta = np.arccos(p_zr[0])\n",
      "../prepareTracks.py:213: RuntimeWarning: invalid value encountered in arccos\n",
      "  theta = np.arccos(p_zr[0])\n",
      "../prepareTracks.py:213: RuntimeWarning: invalid value encountered in arccos\n",
      "  theta = np.arccos(p_zr[0])\n",
      "../prepareTracks.py:213: RuntimeWarning: invalid value encountered in arccos\n",
      "  theta = np.arccos(p_zr[0])\n",
      "../prepareTracks.py:213: RuntimeWarning: invalid value encountered in arccos\n",
      "  theta = np.arccos(p_zr[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 131 ms, sys: 287 ms, total: 417 ms\n",
      "Wall time: 1min 17s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Prepare output\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "logging.info('Writing outputs to ' + output_dir)\n",
    "\n",
    "# Process input files with a worker pool\n",
    "with mp.Pool(processes=n_workers) as pool:\n",
    "    process_func = partial(process_event, output_dir=output_dir,\n",
    "                           phi_range=(-np.pi, np.pi), **config['selection'])\n",
    "    pool.map(process_func, file_prefixes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPU Threading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JIT Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def calc_dphi(phi1, phi2):\n",
    "    \"\"\"Computes phi2-phi1 given in range [-pi,pi]\"\"\"\n",
    "    dphi = phi2 - phi1\n",
    "    dphi[dphi > np.pi] -= 2*np.pi\n",
    "    dphi[dphi < -np.pi] += 2*np.pi\n",
    "    return dphi\n",
    "\n",
    "@njit\n",
    "def calc_eta(r, z):\n",
    "    theta = np.arctan2(r, z)\n",
    "    return -1. * np.log(np.tan(theta / 2.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "x = np.arange(10000000000).reshape(100000, 100000)\n",
    "\n",
    "def go_slow(a): # Function is compiled to machine code when called the first time\n",
    "    trace = 0.\n",
    "    for i in range(a.shape[0]):   # Numba likes loops\n",
    "        trace += np.tanh(a[i, i]) # Numba likes NumPy functions\n",
    "#     return a + trace              # Numba likes NumPy broadcasting\n",
    "\n",
    "@cuda.jit # Set \"nopython\" mode for best performance, equivalent to @njit\n",
    "def go_fast_gpu(a): # Function is compiled to machine code when called the first time\n",
    "    trace = float(0.)\n",
    "    for i in range(a.shape[0]):   # Numba likes loops\n",
    "        trace += float(math.tanh(float(a[i, i]))) # Numba likes NumPy functions\n",
    "#     a = a+trace              # Numba likes NumPy broadcasting\n",
    "\n",
    "@njit # Set \"nopython\" mode for best performance, equivalent to @njit\n",
    "def go_fast(a): # Function is compiled to machine code when called the first time\n",
    "    trace = float(0.)\n",
    "    for i in range(a.shape[0]):   # Numba likes loops\n",
    "        trace += float(math.tanh(float(a[i, i]))) # Numba likes NumPy functions\n",
    "#     a = a+trace              # Numba likes NumPy broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "go_slow(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20 µs, sys: 11 µs, total: 31 µs\n",
      "Wall time: 37.2 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "go_fast(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 316 ms, sys: 757 µs, total: 316 ms\n",
      "Wall time: 315 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "go_fast_gpu(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial investigation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up the inital constraints and choose an event"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select end-cap volumes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is ONLY the end-cap\n",
    "# vlids = [(9,2), (9,4), (9,6), (9,8), (9,10), (9,12), (9,14)]\n",
    "# These are the other front detectors\n",
    "#                     (14,2), (14,4), (14,6), (14,8), (14,10), (14,12),\n",
    "#                     (18,2), (18,4), (18,6), (18,8), (18,10), (18,12)]\n",
    "# These are the barrel volumes\n",
    "vlids = [(8,2), (8,4), (8,6), (8,8),\n",
    "             (13,2), (13,4), (13,6), (13,8),\n",
    "             (17,2), (17,4)]\n",
    "# eta_region = [0,0.2]\n",
    "\n",
    "n_det_layers = len(vlids)\n",
    "vlid_groups = hits.groupby(['volume_id', 'layer_id'])\n",
    "hits = pd.concat([vlid_groups.get_group(vlids[i]).assign(layer=i)\n",
    "                      for i in range(n_det_layers)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "pt = np.sqrt(particles.px**2 + particles.py**2)\n",
    "particles = particles[pt > pt_min]\n",
    "particles = particles.join(pd.DataFrame(pt, columns=[\"pt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "truth = (truth[['hit_id', 'particle_id']]\n",
    "             .merge(particles[['particle_id', 'nhits', 'pt']], on='particle_id'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_hits = np.arccos(hits.z / (hits.x**2 + hits.y**2 + hits.z**2)**(0.5))\n",
    "eta_hits = -np.log(np.tan(theta_hits/2))\n",
    "phi_hits = np.arctan2(hits.y, hits.x)\n",
    "r_hits = np.sqrt(hits.x**2 + hits.y**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create big hits + truth D.F.\n",
    "hits = (hits[['hit_id', 'x', 'y', 'z', 'layer', 'evtid']]\n",
    "            .assign(r=r_hits, phi=phi_hits, eta=eta_hits)\n",
    "            .merge(truth[['hit_id', 'particle_id', 'nhits', 'pt']], on='hit_id'))\n",
    "# Remove duplicated\n",
    "hits = hits.loc[\n",
    "        hits.groupby(['particle_id', 'layer'], as_index=False).r.idxmin()\n",
    "    ]\n",
    "hits = hits[hits['nhits'] > 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = hits.assign(**{'{}'.format(k):v for k,v in zip([\"C\", \"D\",\"E\",\"F\",\"G\"], np.zeros(len(hits)))})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pid in pd.unique(hits['particle_id']):\n",
    "    hits.loc[hits.particle_id == pid, [\"C\", \"D\", \"E\", \"F\", \"G\"]] = get_track_parameters(hits[hits.particle_id == pid]['x'].to_numpy(), hits[hits.particle_id == pid]['y'].to_numpy(), hits[hits.particle_id == pid]['z'].to_numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select certain eta region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "eta_region = [3.2,4]\n",
    "hits = hits[(hits.eta > eta_region[0]) & (hits.eta < eta_region[1])]\n",
    "# hits = hits.sort_values(by='eta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Organise into adjacent layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.arange(n_det_layers)\n",
    "layer_pairs = np.stack([l[:-1], l[1:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['r', 'phi', 'z']\n",
    "feature_scale = np.array([1000., np.pi / n_phi_sections, 1000.])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph, IDs = construct_graph(hits, layer_pairs=layer_pairs,\n",
    "                              phi_slope_max=phi_slope_max, z0_max=z0_max,\n",
    "                              feature_names=feature_names,\n",
    "                              feature_scale=feature_scale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "634  hits and  524  edges\n"
     ]
    }
   ],
   "source": [
    "Ri_rows, Ri_cols = graph.Ri.nonzero()\n",
    "Ro_rows, Ro_cols = graph.Ro.nonzero()\n",
    "n_edges = Ri_cols.shape[0]\n",
    "edge_index = np.zeros((2, n_edges), dtype=int)\n",
    "edge_index[0, Ro_cols] = Ro_rows\n",
    "edge_index[1, Ri_cols] = Ri_rows\n",
    "print(len(graph.X), \" hits and \", edge_index.shape[1], \" edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y, edges, labels = graph.X, graph.y, edge_index, graph.y\n",
    "X = X*feature_scale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch-v1.2.0-gpu [conda env:.conda-numba_env]",
   "language": "python",
   "name": "conda-env-.conda-numba_env-pytorch-v1.2.0-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
